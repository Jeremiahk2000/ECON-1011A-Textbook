\chapter{Consumer Utility}
So far, we have dealt primarily with firms and how they decide what to produce. Now, we address the other side of the market: consumers and how they decide what to buy and consume. However, we need to find a way to convert this to a maximization problem. With firms, we made the very reasonable assumption that they would try to maximize profits. However, with individuals it is less clear what they would be maximizing. In economics, we assume that individuals are maximizing a \vocab{utility function}, which, in a somewhat tautological definition, is simply whatever an individual maximizes when they are making choices. 

\section{What is utility?}
You may have seen utility in previous economics courses described as a quantification of the ``happiness'' of individuals, and the utility function describes how many ``utils'' that an individual receives from consuming certain goods. This may be a useful way of thinking about the utility function and can add some valuable insights, but we want a more formal treatment of utility functions that does not rely on something as abstract and non-specific as representing ``happiness.'' However, this leaves us with a series of problems. Can this happiness be measured and observed? Is it the same across people? Can different types of happiness be compared? In this section, we will explore the formal treatment of utility in economics that defines utility in a way that handles some of these issues and avoids others. It will not be important for you to understand every aspect in this approach, and we will avoid delving into the fully formal technicalities of utility, but it may be useful for you understand where utility comes from to know what you can and cannot do with utility functions.

\subsection*{Utility as preference relations}
We start by approaching the problem of quantifying an individual's preferences by considering a simpler problem: determining whether an individual prefers one outcome over another. Suppose we have two outcomes, $A$ and $B$, for a given individual. These could be any set of outcomes. $A$ might represent receiving 4 apples and $B$ might represent receiving 6 bananas, or $A$ might represent going to Harvard while $B$ is going to Yale.

We have a fairly reasonable to judge whether an individual prefers outcome $A$ or outcome $B$, by observing which they choose when presented with a choice. This means that we can denote a \vocab{preference relation} on outcomes, which expresses which outcome an individual prefers between two outcomes. The notation is as follows:
\begin{itemize}
    \item $A \prec B$ means that the agent strictly prefers $B$ to $A$. That is, given the choice between $A$ and $B$, the agent would choose $B$.
    \item $A \succ B$ means that the agent strictly prefers $A$ to $B$.
    \item $A \sim B$ means that the agent is indifferent between $A$ and $B$.
    \item $A \precsim B$ means that the agent weakly prefers $B$ to $A$. That is, either $A \prec B$ or $A \sim B$.
    \item $A \succsim B$ means that the agent weakly prefers $A$ to $B$.
\end{itemize}
This allows us to rigorously define an individual's preferences by a preference relation on the possible outcomes. However, this alone leaves us with a bit too much room. In order to have useful preferences, we need to assume that agents have \vocab{rational preference}. However, what economists mean by rational preferences is not a normative description of rationality. An economist makes no judgement, for example, on whether prefering chocolate to vanilla ice cream is ``rational.'' Instead, we define rationality by the following two axioms:
\begin{description}
    \item[Completeness] For any two outcomes $A$ and $B$, exactly one of the following holds: $A \prec B$, $A \succ B$, or $A \sim B$. This axiom tells us two things. The first is that the agent always has some preference between any two outcomes, even if that preference is to be indifferent. The second is that an agent cannot simultaneously prefer $A$ to $B$ and prefer $B$ to $A$.
    \item[Transitivity] For any outcomes $A$, $B$, and $C$, $A \precsim B$ and $B \precsim C$ imply that $A \precsim C$. That is, if we prefer $B$ to $A$ and $C$ to $B$, then we must prefer $C$ to $A$ as well.
\end{description}
Whether you think that these axioms are required to be considered rational is up to you, but for the purposes of microeconomics, we impose these requirements and assume our agents to have rational preferences.

\subsection*{From preference relations to utility functions}
Now that we can define an individual's preferences, we can try to convert them into a utility function. A utility function is simply a way of expressing these preference relationships over outcomes by mapping each outcome to a real number, and outcomes that are more preferred have a higher value. Formally:
\begin{definition*}[Utility function]
    A function $u: X \to R$ is a utility function for a preference relation $\precsim$ if for $A, B \in X$, $A \precsim B \iff u(A) \leq u(B)$. 
\end{definition*}
Notice that the utility function for a given set of preferences is not unique. To make the idea of a utilty function more concrete, let's consider a simple example with a finite set of outcomes.
\begin{example*}
    Let $X = \{A, B, C\}$ be the set of outcomes. Maybe $A$ is getting an apple, $B$ is getting a banana, and $C$ is getting a coconut. Suppose we have a preference relation $\precsim$ where $A \precsim B \precsim C$. We want to construct a utility function $u$ that expresses this preference relation. We might define $u$ as follows:
    \begin{align*}
        u(A) = 1, u(B) = 2, u(C) = 3
    \end{align*}
    Notice that because $C$ is preferred to $B$, $u(C)$ is greater than $u(B)$, and the same is true for all pairs of preference relations. However, this is not the unique representation of the preference relations. Define $\tilde{u}$ as the same as $u$ except with the output doubled:
    \begin{align*}
        \tilde{u}(A) = 2, \tilde{u}(B) = 4, \tilde{u}(C) = 6
    \end{align*}
    Notice that this still represents the preference relation $\precsim$, but has different values than $u$ does. 
\end{example*}
The above example illustrates an important point. Utility functions are ordinal, not cardinal. That is, the magnitude of the difference between $u(A)$ and $u(B)$ does not matter, but the sign does. We can state this more formally:

\begin{proposition*}
    Let $u : X \to \R$ be a utility function representing a preference relation $\precsim$. Let $f : \R \to \R$ be a monotonically increasing function. Then $f \circ u: X \to \R$ is also a utility function representing $\precsim$. 
\end{proposition*}
\begin{proof}
    Let $A, B \in X$ where $A \precsim B$. Then $u(A) \leq u(B)$. By monotonicity of $f$, we also have that $f(u(A)) \leq f(u(B))$. Since $A$ and $B$ were arbitrary, this holds for all $A \precsim B$. So, $f \circ u$ is a utility function for $\precsim$. 
\end{proof}
This tells us that we can add, multiply, apply a positive exponent, take logarithms, or apply any monotonic function to a utility function and keep the same underlying preferences. 

However, this also tells us that you \textbf{cannot compare utilities across individuals}. That is, we can not decide that one person is happier than another because they receive more utility, nor can we say that maximizing utility is in general a desirable goal. Those are cases of normative utility functions, but in our case we only deal with the formally defined utility function. Throughout this text and in the course, we may say that higher utility corresponds to an agent being ``happier,'' but this is merely shorthand and to acheive intuition, and should not be interpreted as a claim on utility actually mapping to happiness. 

There is one last wrinkle in our construction of the utility function. In the finite case, or even in the countably infinite case, the above rationality axioms are sufficient to construct a utility function from a preference relation. However, we might have cases where the set of outcomes is uncountably infinitely large. For example, if you have a utility function over how much money you receive, in which case the outcome space is all real numbers. The rationality axioms alone are insufficient to guarantee the existence of a well-defined utilty function for a preference relation over uncountably infinite axioms in this case. So, we need an additional axiom.
\begin{description}
    \item[Contiunity of preferences] For any sequence of outcome pairs, $\{(x^n, y^n)\}_{n = 1}^\infty$ where $x^n \succsim y^n$ for all $n$, and $x = \lim_{n \to \infty} x^n, y = \lim_{n \to \infty} y^n$, then $x \succsim y$. 
\end{description}
The above is a bit more mathematically formal than required in this course, and you do not need to know the continuity property. It basically says that our preference relations are preserved under limits. However, the key is that if $\precsim$ is a continuous preference relation, then we have a \emph{continuous} utility function $u: X \to \R$ representing $\precsim$. 

While this guarantees that there is a continuous utility function, it does not say anything about the differentiability or other properties of the utility function. However, now that we have established the formal mathematical foundations of utility, we can impose more structure to handle the consumer problem specifically. We will do so in the following section.

\section{The consumer's problem}
The consumer's problem is in some sense the foundation of all economics. It has to do with individuals trying to achieve the best outcome that they can. That is, they are maximizing utility. In this section, we describe the basic setup of the model, the assumptions in the model, and some basic properties from solving the model.

\subsection*{Model setup}
We consider a set of $n$ goods that a consumer can consume, and that the consumer chooses real quantities of each good. We denote the choice for amount of these goods $\vec{x} = (x_1, \dots, x_n)$. This means that our space of ``outcomes'' is $X = \R^n$. We assume our agent has a continuously differentiable utility function $u: \R^n \to \R$. We make a few additional asssumptions on the utility function.
\begin{description}
    \item[Increasing in goods] We assume that $u$ is increasing in each good. Mathematically, this is $\partials{u}{x_i} > 0$ for all $i$. A key assumption here is that the consumer wants each good, and that there are no ``bads.'' There will be cases where this assumption no longer holds for a general utility maximization problem (pollution or garbage for example), but in this case we assume the agent can only be happier with there allocation. This also assumes non-satiation, so that agents always want more of the good. 
    \item[Concavity] We assume that $u(\vec{x})$ is concave in $\vec{x}$. Since $u$ is differentiable, this tells us that $\frac{\partial^2 u}{\partial x_i^2} < 0$ for all $x_i$. The intuition here is that agents tend to have diminishing marginal returns. The 10th chocolate bar adds less additional happiness than the first chocolate bar does.
\end{description}

However, there is a slight problem here, which is that clearly the optimal action for an agent given these assumptions is just to consume an infinite amount of everything. In the real world this does not occur because we have a limited amount of money. So we assume that agents have an exogenous fixed income $y$ that can be spent on purchasing goods. Each good $i$ also has a positive price $p_i > 0$, which we assume the agent takes as exogenous, yielding the price vector $\vec{p}$. This implicitly assumes that the agent is a price-taker, so that the amount of good that the agent purchases has no effect on the price, which is the case if the agent is a relatively small spender in an economy with many other consumers and firms to buy from. This gives us the agent's \vocab{budget constraint},
\begin{align*}
    \vec{p} \cdot \vec{x} = \sum_{i = 1}^n p_i x_i \leq y
\end{align*}
So, the consumer's problem can be summarized as follows:
\begin{align*}
    \max_{\vec{x} \in \R^n} u(\vec{x}) \text{ s.t. } \vec{p} \cdot \vec{x} \leq y
\end{align*}

Notice that the budget constraint in this case is an inequality constraint. These are typically more difficult to deal with, but we can simplify the problem by replacing it with an equality constraint. To see why this is the case, consider what would happen if the budget constraint held with strict inequality so that $\vec{p} \cdot \vec{x} < y$. Since buying more of each good increases utility, we could buy some very small additional amount of the first good, say $dx_1$, which would increase utility, while still satisfying the budget constraint. This means that when the agent is optimizing, they must spend their entire budget. We can therefore rewrite the problem,

\begin{align*}
    \max_{\vec{x} \in \R^n} u(\vec{x}) \text{ s.t. } \vec{p} \cdot \vec{x} = y
\end{align*}

\subsection*{Solving the model}
Now that we have set up the model, we will solve it to determine the optimal quantities of goods that consumers should consume. For the sake of simplicity and clarity, we will consider the case of only two goods, $a$ and $b$, with prices $p_a, p_b$ and utility function $u(a, b)$. The consumer's budget is still given as $y$. The problem the consumer solves is therefore
\begin{align*}
    \max_{a, b} u(a, b) \text{ s.t. } p_a a + p_b b = y
\end{align*}

\subsubsection*{Lagrangian method}
Since this is a constrained maximization problem, we can solve it via the standard Lagrangian method. The Lagriangian is
\begin{align*}
    \Lagr(a, b, \lambda) = u(a, b) - \lambda(p_a a + p_b b - y)
\end{align*}
The first order conditions of an optimum are therefore,
\begin{align*}
    \partials{u}{a}(a^*, b^*) &= \lambda^* p_a \\
    \partials{u}{b}(a^*, b^*) &= \lambda^* p_b \\
    p_a a + p_b b &= y
\end{align*}
The third equation is simply the budget constraint. If we divide the first and second equations and rearrange slightly, we obtain,
\begin{align*}
    \frac{\partials{u}{a}}{p_a} = \frac{\partials{u}{b}}{p_b} 
\end{align*}
This tells us that an optimum, the marginal utility per dollar from consuming $a$ must be the same as the marginal utility per dollar from consuming $b$. 

Since we have assumed that $u$ is concave, these conditions define the optimal quantities $a^*(p_a, p_b, y)$ and $b^*(p_a, p_b, y)$. These are called the \vocab{Marshallian demand functions} for $a$ and $b$, which tells us how much an optimizing consumer will buy of a good for given prices and income. Often when writing Marshallian demand, we omit the asterisk to have $a(p_a, p_b, y)$ and $b(p_a, p_b, y)$. Notice that each Marshallian demand is a function of both of the prices as well as the income.

\subsubsection*{Substituting the constraint}
Before moving on, it is worth noting that the Lagrangian method is not the only way to solve a constrained optimization problem. An alternative and often easier method is known as ``substituting in the constraint.'' This relies on the fact that we know that at an optimum, we must have $p_a a + p_b b = y$. One thing we can do then is simply solve for $b$ in terms of the other variables:
\begin{align*}
b = \frac{y - p_a a}{p_b}
\end{align*}
Since this is a constraint, it must always hold even after optimizing. So, we can plug in this constraint into the utility function to obtain $u\left(a, \frac{y - p_a a}{p_b}\right)$. We can then write our new optimization problem as
\begin{align*}
    \max_{a} u\left(a, \frac{y - p_a a}{p_b}\right)
\end{align*}
This is exactly the same as our original problem, except instead of a constrained maximization problem with two variables, we have an unconstrained maximization problem of a single variable. This can dramatically simplify our computations. As always, we take first order conditions by totally differentiating with respect to $a$, 
\begin{align*}
    \partials{u}{a} \left(a^*, \frac{y - p_a a^*}{p_b}\right) - \partials{u}{b}\left(a^*, \frac{y - p_a a^*}{p_b}\right) \frac{p_a}{p_b} = 0
\end{align*}
Rearranging slightly yields,
\begin{align*}
    \frac{\partials{u}{a} \left(a^*, \frac{y - p_a a^*}{p_b}\right)}{p_a} = \frac{\partials{u}{b} \left(a^*, \frac{y - p_a a^*}{p_b}\right)}{p_b}
\end{align*}
Notice that if we were to plug in the fact that $b^* = \frac{y - p_a a^*}{p_b}$, this is the exact same first order condition as we obtained through the Lagrangian method. When solving with an explicit functional form, plugging in the constraint can often make it significantly easier to find the optimal choices.

\section{Value function}
Now that we know how to find the demand functions of optimizing consumers, we can the \vocab{value function}, which is the value of the utility function under optimal consumption. Mathematically, the value function is defined as,
\begin{align*}
    v(\vec{p}, y) = u(\vec{x}^*(\vec{p}, y))
\end{align*}
Where $\vec{x}^*$ is the vector of optimal choice of goods. Notice that the value function is only a function of the exogenous variables, and essentially tells us what is the most utility a consumer can obtain given prices and income. The value function is also known as the \vocab{indirect utility function}. This is analogous to the indirect profit function in the case of firms. Note however that the value function, like the utility function, is ordinal rather than cardinal. 

\subsection*{Properties of indirect utility}
\begin{description}
    \item[Marginal benefit of income] The marginal benefit of income is given by the value of the Lagrange multiplier, $\lambda^*$. That is, $\frac{dv}{dy} = \lambda^*$. In particular, $\frac{dv}{dy} > 0$, which tells us that the more income an individual has, the greater their utility.
    
    The intuition here should be clear. If you have more money than you did before, you can afford the old consumption bundle, and you will have money left over to consume more and make you better off.

    \begin{proof}
        The proof of this fact is analogous to that of the cost function increasing with respect to quantity in \ref{sec:cost_properties}. We use the constrained envelope theorem (\ref{thm:constrained_envelope}).
        \begin{align*}
            \frac{dv}{dy} = \frac{\partial\Lagr^*}{\partial y} = \partials{}{y} \left(u(\vec{x}^*) - \lambda^* (\vec{p} \cdot \vec{x}^* - y)\right) = \lambda^*
        \end{align*}
        That this is positive follows from the first order conditions. Recall that at an optimum, we require 
        \begin{align*}
            \partials{u}{x_i} = \lambda^* p_i
        \end{align*}
        By assumption, we know that $\partials{u}{x_i}, p_i > 0$. So we must have that $\lambda^* = \partials{u}{x_i} / p_i > 0$.
    \end{proof}

    \item[Decreasing in item prices] As the price of a good $i$ increases, the value function increases, $\frac{dv}{dp_i} > 0$. In particular, $\frac{dv}{dp_i} = - \lambda^* p_i$. 
    
    The intuition here is similar to the intuition about incomes. Suppose you had the same or higher utility with the optimal consumption bundle at new prices. Since prices were lower before, you could have purchased the same bundle at the old prices. But since this bundle is different from the old bundle, and the old bundle was optimizing, the new bundle must be worse.

    \begin{proof}
        This proof is also a straightforward application of the constrained envelope theorem (\ref{thm:constrained_envelope}),
        \begin{align*}
            \frac{dv}{dp_i} = \frac{\partial\Lagr^*}{\partial p_i} = \partials{}{p_i} \left(u(\vec{x}^*) - \lambda^* (\vec{p} \cdot \vec{x}^* - y)\right) = -\lambda^* p_i
        \end{align*}
        Since $\lambda^*, p_i > 0$, then $\frac{dv}{dp_i} < 0$. 
    \end{proof}
    \item[Continuous] The value function $v$ is continuous in prices and income. We will not provide a formal mathematical proof of this result. However, this follows from the fact that $u$ is continuous, and the Marshallian demand functions $\vec{x}^*$ are also continuous, so $v = u(\vec{x}^*)$ must be continuous. 
    \item[Quasi-Convexity] At any convex combinations of prices and incomes, the utility obtain must be weakly less than the value function at at least one of the individual prices and incomes. Mathematically, let $\lambda \in [0, 1]$. Fix prices $\vec{p}_0, \vec{p}_1$ and incomes $y_0, y_1$. Define $\vec{p}_\lambda = \lambda p_0 + (1 - \lambda)p_1$ and $y_\lambda = \lambda y_0 + (1 - \lambda) y_1$. Then,
    \begin{align*}
        v(\vec{p}_\lambda, y_\lambda) \leq \max\left\{v(\vec{p}_0, y_0), v(\vec{p}_1, y_1)\right\}
    \end{align*}
    
    Intuitively, the reason this holds is the same as the reason convexity holds for the profit function. If prices are varied, you are able to optimize and achieve a better outcome than if you were at the average of the varied prices.

    \begin{proof}
        The simplest way to prove this is by contradiction. Assume that quasi-convexity does not hold. Then we must have that $v(\vec{p}_\lambda, y_\lambda) > v(\vec{p}_0, y_0)$ and $v(\vec{p}_\lambda, y_\lambda) > v(\vec{p}_1, y_1)$. What must be true for the budget constraints for this to be the case? Because $v(\vec{p}_0, y_0)$ and $v(\vec{p}_1, y_1)$ are optimizing at given prices and incomes, then the allocation chosen with prices $\vec{p}_\lambda$ and income $y_\lambda$, call it $\vec{x}^*_\lambda$, must not satisfy the budget constraints for case 0 or case 1. That is, we must have that $\vec{x}^*_\lambda \cdot \vec{p}_0 > y_0$ and $\vec{x}^*_\lambda \cdot \vec{p}_1 > y_1$. To see why this is the case, if it did satisfy one of the budget constraints, say $\vec{x}^*_\lambda \cdot \vec{p}_0 \leq y_0$, then $v(\vec{p}_0, y_0)$ is optimal, and hence would achieve a weakly greater utility than the utility achieved by $\vec{x}^*_\lambda$.
        
        Next, we can consider how much we spend at prices $\vec{p}_\lambda$ to purchase the allocation, $\vec{x}^*_\lambda$,
        \begin{align*}
            \vec{p}_\lambda \cdot \vec{x}^*_\lambda &= (\lambda \vec{p}_0 + (1 - \lambda) \vec{p}_1) \cdot \vec{x}^*_\lambda \\
            &= \lambda (\vec{p}_0 \cdot \vec{x}^*_\lambda) + (1 - \lambda) (\vec{p}_1 \cdot \vec{x}^*_\lambda) \\
            &> \lambda y_0 + (1 - \lambda) y_1
        \end{align*}
        Where the last line is using the fact that the allocation cannot satisfy either of the original budget constraints. 

        However, recall that $y_\lambda = \lambda y_0 + (1 - \lambda)y_1$. But then plugging into the above inequality yields,
        \begin{align*}
            \vec{p}_\lambda \cdot \vec{x}^*_\lambda > y_\lambda
        \end{align*}
        This violates the budget constraint, and so we know that $\vec{x}^*$ is not in fact a feasible allocation, a contradiction. 
    \end{proof}
\end{description}